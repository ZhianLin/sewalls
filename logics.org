* Logics & Pseudo Code
** Crawler
   Crawler I bertugas mengekstrak single page, sedangkan crawler II bertugas
   mengambil informasi detail terkait dengan wallpaper yang akan dimasukkan
   ke database.
** Database
   Database juga dibuat terpisah:
   - [ ] database url untuk dikonsumsi oleh crawler
   - [ ] database data untuk dikonsumsi oleh aplikasi web
** Format Data
   Format data:
   #+BEGIN_SRC python
     urls = {
         "url": "the_url",
         "status": 0,
         }
   #+END_SRC
   Setelah itu, jalankan crawler kedua untuk mengekstrak beberapa informasi
   berikut dari situs target:
   #+BEGIN_SRC python
     data = {
         "url": "the_url",
         "directlink": "directlink",
         "resolusi": "resolusi",
         "size": "size",
         "dims": "dims",
         }
   #+END_SRC
   Setelah data terkumpul, ubah status dari 0 ke 1, menandakan bahwa url
   sudah dikunjungi oleh crawler II.
* Methods
** Automatic
   Source terbagi menjadi 2, *wp* dan *non-wp*, dari sisi kemudahan *wp* jelas
   lebih mudah, karena biasanya sudah menerapkan sistem pagination, sehingga
   tinggal dilakukan proses /looping/.

   Untuk yang *non-wp*, dilihat dulu dari url, kalo menggunakan sistem url
   berurut, maka tinggal di-/looping/, kalau tidak secara manual gunakan
   /category/.
** Source
*** WP
- [ ] [[highdefinitionwallpapers1080p.com/][highdefinitionwallpapers1080p.com]]
- [ ] [[hdbeachwallpapers.com]]
*** Non WP
- [ ] [[ouchpress.com/celebrities/wallpapers/1861/][ouchpress.com]]
- [ ] [[pichost.me]] #1234567 1648399
- [ ] [[desktopwallpapers4.me/][desktopwallpapers4.me]]
- [ ] [[suffcon.com/][suffcon.com]]
- [ ] [[wallconvert.com/][wallconvert.com]]
- [ ] [[superbwallpapers.com/][superbwallpapers.com]]
- [ ] [[wakpaper.com/][wakpaper.com]]
- [ ] [[girlhdwalls.com/][girlhdwalls.com]]
- [ ] [[wallpaper.mobileinterview.org/][wallpaper.mobileinterview.org]]
- [ ] [[free-hdwallpapers.com/][free-hdwallpapers.com]]
- [ ] [[zastavki.com/][zastavki.com]]
- [ ] [[hdwallpapers.net]]
- [ ] [[santabanta.com/wallpapers/][santabanta.com/wallpapers]]
- [ ] [[3dwallpaperstudio.com/]]
- [ ] [[nevseoboi.com.ua/]]
- [ ] [[bankoboev.ru/]]
- [ ] [[gamewallpapers.com]]
** Manual
   Sesuai namanya, kita browse dan download wallpaper secara manual.
* Challenge
** Prevent from crawl error algo
** Blank referer
   Beberapa situs menerapkan proteksi /blank referer/, yang artinya gambar
   tidak bisa diambil secara serta menggunakan /library/ misal *urllib2*.
   Solusinya adalah dengan menambahkan /header referer/ di /script/ yang
   dibuat, dengan /value/ nama /base domain/.

   Contoh:
   #+BEGIN_SRC python
     import urllib2
     
     req = urllib2.Request("full_url_to.jpg", headers={
         "Referer": "http://www.basedomain.com",
         "User-agent": "Mozilla/5.0",
         })
     data = urllib2.urlopen(req).read()
   #+END_SRC
   Agar lebih meyakinkan, kita dapat membuat beberapa /user-agent/, kemudian
   kita pilih secara /random/ setiap kali melakukan /http request/.
** File naming
   Kalau beruntung, kita mendapatkan file dengan penamaan yang lengkap dan
   merefleksikan isi dari wallpaper tersebut, kalau tidak kita mungkin cuma
   dapat *123.jpg* atau sejenisnya. 

   Bagaimana membuat nama file yang merefleksikan isi dari gambar?
* What to do next
  Setelah data terkumpul /cukup/ banyak, aplikasi ini diautomasi dengan 
  mengandalkan rss feed wallpaper yang banyak bertebaran di luar sana.
